"""
æµ‹è¯•LLMè°ƒç”¨Tavilyæœç´¢å·¥å…·çš„èƒ½åŠ›
åŒ…æ‹¬éæµå¼å’Œæµå¼ä¸¤ç§è°ƒç”¨æ–¹å¼
"""

import asyncio
import os
import sys
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from llm import LLM
from tools.tavily_search import tavily_search
from tools.function_schema import tools

async def test_non_stream():
    """æµ‹è¯•éæµå¼è°ƒç”¨Tavilyæœç´¢"""
    print("="*60)
    print("ğŸ” æµ‹è¯•éæµå¼æœç´¢")
    print("="*60)
    
    # åˆå§‹åŒ–LLM
    llm = LLM(
        api_key="sk-f5889d58c6db4dd38ca78389a6c7a7e8",  # DeepSeek API key
        base_url="https://api.deepseek.com/v1",
        model="deepseek-chat",
        temperature=0.7
    )
    
    # è®¾ç½®ç³»ç»Ÿæç¤º
    llm.add_message("system", """
    ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½æœç´¢åŠ©æ‰‹ã€‚å½“ç”¨æˆ·è¯¢é—®éœ€è¦å®æ—¶ä¿¡æ¯çš„é—®é¢˜æ—¶ï¼Œä½¿ç”¨tavily_searchå·¥å…·è¿›è¡Œæœç´¢ã€‚
    æœç´¢åï¼ŒåŸºäºæœç´¢ç»“æœç»™å‡ºç®€æ´å‡†ç¡®çš„å›ç­”ã€‚
    """)
    
    # å·¥å…·é…ç½®
    tools = tools
    tool_functions = {
        "tavily_search": tavily_search
    }
    
    # æµ‹è¯•æŸ¥è¯¢
    query = "2024å¹´è¯ºè´å°”ç‰©ç†å­¦å¥–è·å¾—è€…æ˜¯è°ï¼Ÿä»–ä»¬çš„ä¸»è¦è´¡çŒ®æ˜¯ä»€ä¹ˆï¼Ÿ"
    print(f"[ç”¨æˆ·]: {query}\n")
    
    # éæµå¼è°ƒç”¨
    response = await llm.chat_complete(
        user_input=query,
        tools=tools,
        tool_functions=tool_functions,
        verbose=True,  # æ‰“å°è¯¦ç»†ä¿¡æ¯
        max_tool_rounds=2  # æœ€å¤š2è½®æœç´¢
    )
    
    print(f"\n[æœ€ç»ˆå›ç­”]: {response}")
    
    # æ‰“å°å¯¹è¯å†å²
    print("\nğŸ“ å¯¹è¯å†å²ï¼š")
    for i, msg in enumerate(llm.get_history(), 1):
        role = msg['role']
        content = msg.get('content', '')
        if content:
            content_preview = content[:100] + "..." if len(content) > 100 else content
            print(f"{i}. [{role}]: {content_preview}")
        if 'tool_calls' in msg:
            print(f"   [å·¥å…·è°ƒç”¨]: {msg['tool_calls'][0]['function']['name']}")

async def test_stream():
    """æµ‹è¯•æµå¼è°ƒç”¨Tavilyæœç´¢"""
    print("\n" + "="*60)
    print("ğŸ”„ æµ‹è¯•æµå¼æœç´¢")
    print("="*60)
    
    # åˆå§‹åŒ–æ–°çš„LLMå®ä¾‹
    llm = LLM(
        api_key="sk-f5889d58c6db4dd38ca78389a6c7a7e8",
        base_url="https://api.deepseek.com/v1",
        model="deepseek-chat",
        temperature=0.7
    )
    
    # è®¾ç½®ç³»ç»Ÿæç¤º
    llm.add_message("system", """
    ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½æœç´¢åŠ©æ‰‹ã€‚ä½¿ç”¨tavily_searchå·¥å…·è·å–æœ€æ–°ä¿¡æ¯ã€‚
    åŸºäºæœç´¢ç»“æœæä¾›å‡†ç¡®çš„ç­”æ¡ˆã€‚
    """)
    
    # å·¥å…·é…ç½®
    tools = tools
    tool_functions = {
        "tavily_search": tavily_search
    }
    
    # æµ‹è¯•æŸ¥è¯¢
    query = "ä»Šå¤©çš„ç§‘æŠ€æ–°é—»æœ‰å“ªäº›é‡è¦äº‹ä»¶ï¼Ÿ"
    print(f"[ç”¨æˆ·]: {query}\n")
    
    # æµå¼è°ƒç”¨
    print("[åŠ©æ‰‹]: ", end="", flush=True)
    
    async for chunk in llm.chat_stream(
        user_input=query,
        tools=tools,
        tool_functions=tool_functions,
        max_tool_rounds=2
    ):
        if chunk["type"] == "content":
            # å®æ—¶è¾“å‡ºæ–‡æœ¬å†…å®¹
            print(chunk["data"], end="", flush=True)
        
        elif chunk["type"] == "tool_execution_start":
            print("\n[ç³»ç»Ÿ]: å¼€å§‹æ‰§è¡Œå·¥å…·è°ƒç”¨...")
        
        elif chunk["type"] == "tool_executing":
            tool_name = chunk["data"]["name"]
            args = chunk["data"].get("arguments", {})
            print(f"[å·¥å…·]: è°ƒç”¨ {tool_name}")
            if "query" in args:
                print(f"        æœç´¢è¯: {args['query']}")
        
        elif chunk["type"] == "tool_result":
            result_preview = chunk["data"]["result"][:200] + "..."
            print(f"[ç»“æœ]: {result_preview}")
            print("[åŠ©æ‰‹]: ", end="", flush=True)
        
        elif chunk["type"] == "continue_generation":
            round_num = chunk["data"]["round"]
            print(f"\n[ç³»ç»Ÿ]: ç»§ç»­ç”Ÿæˆï¼ˆç¬¬{round_num}è½®ï¼‰...")
            print("[åŠ©æ‰‹]: ", end="", flush=True)
        
        elif chunk["type"] == "system_info":
            print(f"\n[ç³»ç»Ÿ]: {chunk['data']}")
            print("[åŠ©æ‰‹]: ", end="", flush=True)
    
    print()  # æ¢è¡Œ

async def test_multi_round_search():
    """æµ‹è¯•å¤šè½®æœç´¢èƒ½åŠ›"""
    print("\n" + "="*60)
    print("ğŸ”„ æµ‹è¯•å¤šè½®æœç´¢å¯¹è¯")
    print("="*60)
    
    llm = LLM(
        api_key="sk-f5889d58c6db4dd38ca78389a6c7a7e8",
        base_url="https://api.deepseek.com/v1",
        model="deepseek-chat",
        temperature=0.7
    )
    
    llm.add_message("system", "ä½ æ˜¯ä¸€ä¸ªç ”ç©¶åŠ©æ‰‹ï¼Œå¯ä»¥è¿›è¡Œæ·±å…¥çš„ä¿¡æ¯æœç´¢å’Œåˆ†æã€‚")
    
    tools = [tavily_search_schema]
    tool_functions = {"tavily_search": tavily_search}
    
    # ç¬¬ä¸€ä¸ªé—®é¢˜
    print("[ç”¨æˆ·]: ä»€ä¹ˆæ˜¯é‡å­è®¡ç®—ï¼Ÿ")
    response1 = await llm.chat_complete(
        user_input="ä»€ä¹ˆæ˜¯é‡å­è®¡ç®—ï¼Ÿ",
        tools=tools,
        tool_functions=tool_functions,
        verbose=False
    )
    print(f"[åŠ©æ‰‹]: {response1}\n")
    
    # åç»­é—®é¢˜ï¼ˆåŸºäºä¸Šä¸‹æ–‡ï¼‰
    print("[ç”¨æˆ·]: å®ƒä¸ä¼ ç»Ÿè®¡ç®—æœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ")
    response2 = await llm.chat_complete(
        user_input="å®ƒä¸ä¼ ç»Ÿè®¡ç®—æœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ",
        tools=tools,
        tool_functions=tool_functions,
        verbose=False
    )
    print(f"[åŠ©æ‰‹]: {response2}\n")
    
    # éœ€è¦æ–°æœç´¢çš„é—®é¢˜
    print("[ç”¨æˆ·]: ç›®å‰æœ‰å“ªäº›å…¬å¸åœ¨ç ”å‘é‡å­è®¡ç®—æœºï¼Ÿ")
    response3 = await llm.chat_complete(
        user_input="ç›®å‰æœ‰å“ªäº›å…¬å¸åœ¨ç ”å‘é‡å­è®¡ç®—æœºï¼Ÿ",
        tools=tools,
        tool_functions=tool_functions,
        verbose=True,
        max_tool_rounds=2
    )
    print(f"\n[æœ€ç»ˆå›ç­”]: {response3}")

async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("\nğŸš€ å¼€å§‹æµ‹è¯• LLM + Tavily æœç´¢å·¥å…·\n")
    
    # æ£€æŸ¥ç¯å¢ƒå˜é‡
    if not os.getenv("TAVILY_API_KEY"):
        print("âš ï¸ è­¦å‘Š: æœªè®¾ç½® TAVILY_API_KEY ç¯å¢ƒå˜é‡")
        print("è¯·è®¾ç½®: export TAVILY_API_KEY='your-api-key'")
        print("ç»§ç»­æµ‹è¯•ï¼ˆå¯èƒ½ä¼šå¤±è´¥ï¼‰...\n")
    
    try:
        # æµ‹è¯•éæµå¼
        await test_non_stream()
        
        # æµ‹è¯•æµå¼
        await test_stream()
        
        # æµ‹è¯•å¤šè½®å¯¹è¯
        await test_multi_round_search()
        
        print("\nâœ… æ‰€æœ‰æµ‹è¯•å®Œæˆï¼")
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    # è®¾ç½® Tavily API Keyï¼ˆå¦‚æœè¿˜æ²¡è®¾ç½®ï¼‰
    if not os.getenv("TAVILY_API_KEY"):
        # è¿™é‡Œæ›¿æ¢ä¸ºä½ çš„å®é™… API key
        os.environ["TAVILY_API_KEY"] = "tvly-YOUR_ACTUAL_API_KEY"
    
    asyncio.run(main())