"""Webæœç´¢Agentä¼šè¯å±‚ - æ”¯æŒçœŸæ­£çš„æµå¼ä¼ è¾“"""

import asyncio
import json
from typing import Optional, Dict, List, Literal, Any, AsyncGenerator
from llm_0908 import LLM
from tools.tavily_search import tavily_search
from tools.function_schema import tools

class WebSearchAgent:
   """Webæœç´¢Agentä¼šè¯ç®¡ç†ç±»"""
   
   def __init__(self,
                api_key: str,
                base_url: str = "https://api.deepseek.com/v1",
                model: str = "deepseek-chat",
                tool_choice: Literal["auto", "required", "none"] = "auto",
                max_tool_calls: int = 3,
                temperature: float = 0.7,
                max_tokens: int = 4096,
                stream: bool = True):
       """
       Args:
           api_key: DeepSeek APIå¯†é’¥
           base_url: APIåŸºç¡€URL
           model: æ¨¡å‹åç§°
           tool_choice: å·¥å…·é€‰æ‹©æ¨¡å¼ ("auto", "required", "none")
           max_tool_calls: å•æ¬¡å¯¹è¯æœ€å¤§å·¥å…·è°ƒç”¨æ¬¡æ•°
           temperature: æ¸©åº¦å‚æ•°
           max_tokens: æœ€å¤§tokens
           stream: æ˜¯å¦æµå¼è¾“å‡º
       """
       # max_tokenså‚æ•°ç”¨äºæ§åˆ¶å¤§æ¨¡å‹æ¯æ¬¡ç”Ÿæˆå›å¤æ—¶çš„æœ€å¤§tokenï¼ˆæ ‡è®°ï¼‰æ•°ã€‚
       # å®ƒå†³å®šäº†æ¨¡å‹è¾“å‡ºå†…å®¹çš„é•¿åº¦ä¸Šé™ï¼Œé˜²æ­¢ç”Ÿæˆè¿‡é•¿çš„å›å¤å¯¼è‡´æ¶ˆè€—è¿‡å¤šèµ„æºæˆ–è¶…å‡ºæ¥å£é™åˆ¶ã€‚
       # ä¾‹å¦‚ï¼Œmax_tokens=4096è¡¨ç¤ºå•æ¬¡å›å¤æœ€å¤šç”Ÿæˆ4096ä¸ªtokenï¼Œè¶…å‡ºéƒ¨åˆ†ä¼šè¢«æˆªæ–­ã€‚
       self.llm = LLM(
           api_key=api_key,
           base_url=base_url,
           model=model,
           tool_choice=tool_choice,
           temperature=temperature,
           max_tokens=max_tokens,
           stream=stream
       )
       
       self.tool_choice = tool_choice
       self.max_tool_calls = max_tool_calls
       self.tool_call_count = 0  # å½“å‰å¯¹è¯å·¥å…·è°ƒç”¨è®¡æ•°
       
       # å·¥å…·å‡½æ•°æ˜ å°„
       self.tool_functions = {
           "tavily_search": tavily_search
       }
       
       # session_activeå‚æ•°ç”¨äºç®¡ç†å½“å‰ä¼šè¯æ˜¯å¦å¤„äºæ¿€æ´»çŠ¶æ€ï¼ˆå³æ˜¯å¦ç»§ç»­ä¸ç”¨æˆ·äº¤äº’ï¼‰ã€‚
       # å½“session_activeä¸ºTrueæ—¶ï¼ŒAgentä¼šæŒç»­æ¥æ”¶å’Œå¤„ç†ç”¨æˆ·è¾“å…¥ï¼›
       # å¦‚æœè®¾ç½®ä¸ºFalseï¼Œåˆ™ä¼šè¯ç»ˆæ­¢ï¼ŒAgentä¸å†å“åº”æ–°çš„æ¶ˆæ¯ï¼ˆå¦‚ç”¨æˆ·è¾“å…¥/exitå‘½ä»¤æ—¶ï¼‰ã€‚
       self.session_active = True 
       self.system_prompt = """ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ï¼Œå¯ä»¥é€šè¿‡æœç´¢å·¥å…·è·å–æœ€æ–°çš„äº’è”ç½‘ä¿¡æ¯ã€‚

æœç´¢ç­–ç•¥æŒ‡å¯¼ï¼š
1. å½“ç”¨æˆ·è¯¢é—®éœ€è¦å®æ—¶ä¿¡æ¯çš„é—®é¢˜æ—¶ï¼Œä½¿ç”¨æœç´¢å·¥å…·
2. å¦‚æœé¦–æ¬¡æœç´¢ç»“æœä¸å¤Ÿå……åˆ†æˆ–ç›¸å…³ï¼Œå¯ä»¥è¿›è¡Œå¤šè½®æœç´¢ï¼š
   - å°è¯•ä¸åŒçš„æœç´¢å…³é”®è¯
   - ä½¿ç”¨æ›´å…·ä½“æˆ–æ›´å®½æ³›çš„æœç´¢è¯
   - åŸºäºå‰æ¬¡æœç´¢ç»“æœè°ƒæ•´æœç´¢ç­–ç•¥
3. æœ€å¤šå¯ä»¥è¿›è¡Œ3æ¬¡æœç´¢ï¼Œè¯·åˆç†åˆ©ç”¨æœç´¢æ¬¡æ•°
4. åŸºäºæ‰€æœ‰æœç´¢ç»“æœæä¾›å‡†ç¡®ã€å…¨é¢ã€æœ‰å¸®åŠ©çš„å›ç­”

æœç´¢è´¨é‡è¯„ä¼°ï¼š
- å¦‚æœæœç´¢ç»“æœä¸ç”¨æˆ·é—®é¢˜é«˜åº¦ç›¸å…³ä¸”ä¿¡æ¯å……åˆ†ï¼Œå¯ä»¥åœæ­¢æœç´¢
- å¦‚æœæœç´¢ç»“æœä¸å¤Ÿç›¸å…³æˆ–ä¿¡æ¯ä¸è¶³ï¼Œç»§ç»­ä¼˜åŒ–æœç´¢ç­–ç•¥"""
       
       # åˆå§‹åŒ–æ—¶æ³¨å…¥ç³»ç»Ÿæç¤ºï¼ˆåˆ°conversation_historyï¼‰
       self.llm.add_message("system", self.system_prompt)
   
   def reset_session(self):
       """é‡ç½®ä¼šè¯çŠ¶æ€"""
       self.llm.clear_history()
       self.tool_call_count = 0
       # é‡æ–°æ³¨å…¥ç³»ç»Ÿæç¤ºï¼ˆåˆ°conversation_historyï¼‰
       self.llm.add_message("system", self.system_prompt)
       print("âœ¨ ä¼šè¯å·²é‡ç½®\n")
   
   def set_tool_choice(self, choice: Literal["auto", "required", "none"]):
       """è®¾ç½®å·¥å…·é€‰æ‹©æ¨¡å¼"""
       self.tool_choice = choice
       self.llm.tool_choice = choice
       print(f"ğŸ”§ å·¥å…·é€‰æ‹©æ¨¡å¼è®¾ç½®ä¸º: {choice}\n")
   
   def set_max_tool_calls(self, max_calls: int):
       """è®¾ç½®æœ€å¤§å·¥å…·è°ƒç”¨æ¬¡æ•°"""
       self.max_tool_calls = max_calls
       print(f"ğŸ“Š æœ€å¤§å·¥å…·è°ƒç”¨æ¬¡æ•°è®¾ç½®ä¸º: {max_calls}\n")
   
   def set_stream_mode(self, stream: bool):
       """è®¾ç½®æµå¼è¾“å‡ºæ¨¡å¼"""
       self.llm.stream = stream
       mode_str = "æµå¼" if stream else "éæµå¼"
       print(f"ğŸ“¡ è¾“å‡ºæ¨¡å¼è®¾ç½®ä¸º: {mode_str}\n")
   
   async def process_message_stream(self, user_input: str) -> AsyncGenerator[Dict[str, Any], None]:
       """æµå¼å¤„ç†å•æ¡ç”¨æˆ·æ¶ˆæ¯ï¼ˆç®€åŒ–ç‰ˆï¼Œå®Œå…¨å¤ç”¨LLMç±»é€»è¾‘ï¼‰"""
       self.tool_call_count = 0
       
       try:
           async for chunk in self.llm.chat_with_tools_stream(
               user_input=user_input,
               tools=None if self.tool_choice == "none" else tools,
               tool_functions=self.tool_functions
           ):
               # ä»…å¤„ç†å·¥å…·è°ƒç”¨æ¬¡æ•°é™åˆ¶
               if chunk["type"] == "tool_executing":
                   self.tool_call_count += 1
                   if self.tool_call_count > self.max_tool_calls:
                       self.llm.add_message(
                           "tool", 
                           f"[å·²è¾¾åˆ°{self.max_tool_calls}æ¬¡è°ƒç”¨ä¸Šé™]",
                           tool_call_id="limit"
                       )
                       yield {"type": "tool_limit", "data": f"è¾¾åˆ°ä¸Šé™{self.max_tool_calls}æ¬¡"}
                       break
               
               # é€ä¼ æ‰€æœ‰å…¶ä»–äº‹ä»¶
               yield chunk
               
       except Exception as e:
           yield {"type": "error", "data": f"å¤„ç†æ¶ˆæ¯æ—¶å‡ºé”™: {str(e)}"}
   
   
   async def process_message(self, user_input: str) -> str:
       """éæµå¼å¤„ç†å•æ¡ç”¨æˆ·æ¶ˆæ¯"""
       tools_to_use = None if self.tool_choice == "none" else tools
       
       try:
           return await self.llm.chat_with_tools(
               user_input=user_input,
               tools=tools_to_use,
               tool_functions=self.tool_functions,
               stream=False
           )
       except Exception as e:
           return f"å¤„ç†æ¶ˆæ¯æ—¶å‡ºé”™: {str(e)}"

# ============================================
# æµ‹è¯•å…¥å£
# ============================================

async def main():
   """æµ‹è¯•å…¥å£"""
   agent = WebSearchAgent(
       api_key="sk-f5889d58c6db4dd38ca78389a6c7a7e8",  
       tool_choice="auto",
       max_tool_calls=3,
       stream=True
   )
   
   # ç®€å•æµ‹è¯•
   print("æµ‹è¯•WebSearchAgent...")
   result = await agent.process_message("ä»Šå¤©åŒ—äº¬çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ")
   print(f"ç»“æœ: {result}")

if __name__ == "__main__":
   asyncio.run(main())